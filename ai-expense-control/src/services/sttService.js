const OpenAI = require('openai');
const fs = require('fs').promises;
const path = require('path');
const { logger } = require('../utils/logger');

// Inicializar OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

/**
 * Processa √°udio de voz usando STT
 * @param {string} audioPath - Caminho do arquivo de √°udio
 * @returns {Promise<Object>} - Resultado do STT
 */
async function processAudio(audioPath) {
  try {
    logger.info(`üé§ Processando √°udio: ${audioPath}`);

    // Verificar se o arquivo existe
    await fs.access(audioPath);

    // Ler o arquivo de √°udio
    const audioBuffer = await fs.readFile(audioPath);
    
    // Converter √°udio para texto usando OpenAI Whisper
    const transcription = await openai.audio.transcriptions.create({
      file: new Blob([audioBuffer], { type: 'audio/mpeg' }),
      model: 'whisper-1',
      language: 'pt', // Portugu√™s
      response_format: 'text'
    });

    const extractedText = transcription;
    
    logger.info(`‚úÖ STT conclu√≠do`);
    logger.debug(`üìù Texto extra√≠do: ${extractedText}`);

    return {
      text: extractedText,
      originalPath: audioPath,
      processed: true,
      model: 'whisper-1'
    };

  } catch (error) {
    logger.error('‚ùå Erro no processamento STT:', error);
    
    // Fallback: tentar com outras configura√ß√µes
    if (error.message.includes('language')) {
      logger.info('üîÑ Tentando sem especificar idioma...');
      return await processAudioFallback(audioPath);
    }
    
    throw new Error(`Falha no STT: ${error.message}`);
  }
}

/**
 * Fallback para processamento de √°udio
 * @param {string} audioPath - Caminho do arquivo de √°udio
 * @returns {Promise<Object>} - Resultado do STT
 */
async function processAudioFallback(audioPath) {
  try {
    const audioBuffer = await fs.readFile(audioPath);
    
    const transcription = await openai.audio.transcriptions.create({
      file: new Blob([audioBuffer], { type: 'audio/mpeg' }),
      model: 'whisper-1',
      response_format: 'text'
    });

    return {
      text: transcription,
      originalPath: audioPath,
      processed: true,
      model: 'whisper-1-fallback'
    };

  } catch (error) {
    logger.error('‚ùå Erro no fallback STT:', error);
    throw new Error(`Falha no STT (fallback): ${error.message}`);
  }
}

/**
 * Processa √°udio usando OpenAI com prompt espec√≠fico para gastos
 * @param {string} audioPath - Caminho do arquivo de √°udio
 * @returns {Promise<Object>} - Resultado do STT com contexto
 */
async function processAudioWithContext(audioPath) {
  try {
    logger.info(`üé§ Processando √°udio com contexto: ${audioPath}`);

    const audioBuffer = await fs.readFile(audioPath);
    
    // Usar Whisper com prompt espec√≠fico para gastos
    const transcription = await openai.audio.transcriptions.create({
      file: new Blob([audioBuffer], { type: 'audio/mpeg' }),
      model: 'whisper-1',
      language: 'pt',
      response_format: 'text',
      prompt: 'Esta √© uma mensagem sobre gastos financeiros, compras, despesas, valores, estabelecimentos, datas e categorias de despesas.'
    });

    const extractedText = transcription;
    
    logger.info(`‚úÖ STT com contexto conclu√≠do`);
    logger.debug(`üìù Texto extra√≠do: ${extractedText}`);

    return {
      text: extractedText,
      originalPath: audioPath,
      processed: true,
      model: 'whisper-1-context',
      hasContext: true
    };

  } catch (error) {
    logger.error('‚ùå Erro no STT com contexto:', error);
    // Fallback para STT normal
    return await processAudio(audioPath);
  }
}

/**
 * Valida se o arquivo de √°udio √© suportado
 * @param {string} audioPath - Caminho do arquivo
 * @returns {boolean} - Se √© suportado
 */
function isAudioSupported(audioPath) {
  const supportedFormats = ['.mp3', '.wav', '.ogg', '.m4a', '.flac'];
  const ext = path.extname(audioPath).toLowerCase();
  return supportedFormats.includes(ext);
}

/**
 * Converte √°udio para formato suportado se necess√°rio
 * @param {string} audioPath - Caminho do arquivo original
 * @returns {Promise<string>} - Caminho do arquivo convertido
 */
async function convertAudioIfNeeded(audioPath) {
  // Por enquanto, retorna o caminho original
  // Implementar convers√£o se necess√°rio
  return audioPath;
}

module.exports = {
  processAudio,
  processAudioWithContext,
  processAudioFallback,
  isAudioSupported,
  convertAudioIfNeeded
};
